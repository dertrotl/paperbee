# .github/workflows/daily_paper_marr.yml
name: PaperBee Daily Digest MarrPeng

on:
  schedule:
    - cron: '0 6 * * 1-5'  # Monday-Friday at 6 AM UTC (8 AM German time during DST)
  workflow_dispatch:

jobs:
  fetch-papers:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install -e .
          
      - name: Create Google credentials file
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS_JSON }}' > google-credentials.json
          
      - name: Determine search window
        id: search_days
        run: |
          DAY_OF_WEEK=$(date +%u)
          if [ "$DAY_OF_WEEK" -eq 1 ]; then
            echo "since_days=2" >> $GITHUB_OUTPUT
          else
            echo "since_days=1" >> $GITHUB_OUTPUT
          fi
          
      - name: Run Multi-Group Pipeline
        env:
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SPREADSHEET_ID_2 }}
          NCBI_KEY: ${{ secrets.NCBI_API_KEY }}
          GEMINI_KEY: ${{ secrets.GEMINI_API_KEY }}
          SLACK_BOT: ${{ secrets.SLACK_BOT_TOKEN_2 }}
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL_ID_2 }}
          SLACK_APP: ${{ secrets.SLACK_APP_TOKEN_2 }}
        run: |
          echo "üî¨ Starting PaperBee Multi-Group Research Digest"
          echo "üìÖ Search window: ${{ steps.search_days.outputs.since_days }} days"
          echo ""
          
          python3 << 'EOF'
          import yaml
          import os
          import json
          import subprocess
          import tempfile
          from pathlib import Path
          
          # Define three focused interest groups for MarrLab
          interest_groups = {
              "Happy Pixels": {
                  "emoji": "üñºÔ∏è",
                  "query_biorxiv": "[computational pathology] OR [cell segmentation] OR [image analysis] OR [microscopy] OR [fluorescence microscopy] OR [biomedical imaging] OR [machine learning] OR [deep learning] OR [AI] OR [computer vision] OR [image processing] OR [cell detection] OR [cell classification] OR [foundation models] OR [self-supervised learning] OR [representation learning] OR [morphological profiling] OR [organoid] OR [3D imaging] OR [holography]",
                  "query_pubmed_arxiv": "[computational pathology] OR [cell segmentation] OR [microscopy image analysis] OR [AI microscopy] OR [biomedical image analysis] OR [deep learning medical] OR [machine learning pathology] OR [cell classification] OR [cell detection] OR [foundation models] OR [self-supervised learning] OR [multiple instance learning] OR [holography] OR [digital in-line holography] OR [3D segmentation] OR [Vision language model] OR [morphological profiling] OR [cell painting] OR [representation learning] OR [organoid detection and segmentation]",
                  "filter": "You are a lab manager at a research lab focusing on computational pathology, microscopy image analysis, and AI/ML applications in biomedical imaging. The lab develops machine learning algorithms for cell segmentation, image processing, and computational analysis of microscopic images. Research areas include foundation models, computer vision, deep learning for medical imaging, and AI-based image analysis. Lab members are interested in computational pathology, microscopy, image analysis, cell detection and classification, and AI applications in life sciences. Be INCLUSIVE - if a paper relates to image analysis, microscopy, AI/ML in biomedical contexts, computer vision, or computational methods for biological imaging, it is likely relevant. You are reviewing research papers to determine if they are relevant to your lab. Please answer 'yes' or 'no' to the following question: Is the following research paper relevant?",
                  "limit": 400,
                  "limit_per_database": 150
              },
              "Omics and Dynamics": {
                  "emoji": "üß¨",
                  "query_biorxiv": "[hematopoiesis] OR [clonal hematopoiesis] OR [single cell] OR [scRNA-seq] OR [multiomics] OR [computational biology] OR [mathematical modeling] OR [clonal dynamics] OR [blood disorders] OR [hematology] OR [single cell profiling] OR [genomics] OR [transcriptomics] OR [proteomics] OR [systems biology] OR [mechanistic modeling] OR [time series] OR [drug discovery] OR [biomarker discovery]",
                  "query_pubmed_arxiv": "[clonal hematopoiesis] OR [CHIP] OR [hematopoiesis] OR [haematopoiesis] OR [clonal dynamics] OR [mechanistic modeling] OR [mechanistic modelling] OR [single cell profiling] OR [multi-omics] OR [multiomics] OR [computational biology] OR [mathematical modeling biology] OR [time-resolved modeling] OR [drug target identification] OR [computational hematology] OR [blood disorders] OR [computational hematopathology] OR [large language models healthcare] OR [AI healthcare]",
                  "filter": "You are a lab manager at a research lab focusing on computational hematology, blood disorders, and quantitative biology. Key research areas include hematopoiesis, clonal dynamics, mathematical modeling of biological systems, and multi-omics approaches. The lab works with single-cell data, computational biology, mechanistic modeling, and quantitative analysis of hematological processes. Research focuses on blood disorders, hematopoiesis, single-cell profiling, multi-omics integration, and computational approaches to understanding biological systems. Be INCLUSIVE - if a paper relates to hematology, blood disorders, single-cell analysis, computational biology, mathematical modeling, multi-omics, or quantitative approaches to biological systems, it is likely relevant. You are reviewing research papers to determine if they are relevant to your lab. Please answer 'yes' or 'no' to the following question: Is the following research paper relevant?",
                  "limit": 400,
                  "limit_per_database": 150
              },
              "Histopathology": {
                  "emoji": "üî¨",
                  "query_biorxiv": "[computational pathology] OR [digital pathology] OR [hematology] OR [blood disorders] OR [pathology] OR [machine learning] OR [AI] OR [deep learning] OR [microscopy] OR [image analysis] OR [cell analysis] OR [biomedical imaging] OR [cancer] OR [tumor] OR [diagnostic] OR [biomarker] OR [computational medicine] OR [medical AI]",
                  "query_pubmed_arxiv": "[hematology] OR [haematology] OR [blood disorders] OR [computational hematopathology] OR [computational pathology] OR [machine learning pathology] OR [AI microscopy] OR [cell classification] OR [cell detection] OR [quantitative microscopy] OR [fluorescence microscopy] OR [cryo-electron microscopy] OR [image processing] OR [deep learning medical] OR [foundation models] OR [self-supervised learning] OR [multiple instance learning] OR [biomedical image analysis]",
                  "filter": "You are a lab manager at a research lab focusing on computational pathology, hematopathology, and medical AI applications. The lab develops AI/ML methods for pathological analysis, medical image processing, and diagnostic applications. Key research areas include hematology, blood disorders, computational pathology, and AI-based diagnostic tools. The lab works with medical imaging, pathological data analysis, and computational approaches to disease diagnosis and treatment. Be INCLUSIVE - if a paper relates to hematology, blood disorders, pathology, medical AI, diagnostic applications, medical imaging, or computational approaches to medicine, it is likely relevant. You are reviewing research papers to determine if they are relevant to your lab. Please answer 'yes' or 'no' to the following question: Is the following research paper relevant?",
                  "limit": 400,
                  "limit_per_database": 150
              }
          }
          
          all_papers = []
          
          print(f"üéØ PROCESSING OVERVIEW:")
          for i, (group_name, group_config) in enumerate(interest_groups.items(), 1):
              biorxiv_terms = len(group_config['query_biorxiv'].split(' OR '))
              pubmed_terms = len(group_config['query_pubmed_arxiv'].split(' OR '))
              print(f"  {i}. {group_config['emoji']} {group_name}: {biorxiv_terms} bioRxiv terms, {pubmed_terms} PubMed/ArXiv terms")
          print("")
          
          for group_name, group_config in interest_groups.items():
              print(f"\n{group_config['emoji']} Processing {group_name} group...")
              
              # Create config for this group
              config = {
                  "GOOGLE_SPREADSHEET_ID": os.environ.get("GOOGLE_SHEET_ID", ""),
                  "GOOGLE_CREDENTIALS_JSON": "./google-credentials.json",
                  "NCBI_API_KEY": os.environ.get("NCBI_KEY", ""),
                  "LOCAL_ROOT_DIR": ".",
                  "databases": ["pubmed", "arxiv", "biorxiv"],
                  "query_biorxiv": group_config["query_biorxiv"],
                  "query_pubmed_arxiv": group_config["query_pubmed_arxiv"],
                  "limit": group_config["limit"],
                  "limit_per_database": group_config["limit_per_database"],
                  "LLM_FILTERING": True,
                  "LLM_PROVIDER": "openai",
                  "LANGUAGE_MODEL": "gemini-2.5-flash-lite",
                  "OPENAI_API_KEY": os.environ.get("GEMINI_KEY", ""),
                  "OPENAI_BASE_URL": "https://generativelanguage.googleapis.com/v1beta/openai/",
                  "FILTERING_PROMPT": group_config["filter"],
                  "SLACK": {
                      "is_posting_on": True,
                      "bot_token": os.environ.get("SLACK_BOT", ""),
                      "channel_id": os.environ.get("SLACK_CHANNEL", ""),
                      "app_token": os.environ.get("SLACK_APP", "")
                  },
                  "TELEGRAM": {"is_posting_on": False},
                  "ZULIP": {"is_posting_on": False}
              }
              
              # Create temporary config file
              config_file = f"config_{group_name.lower().replace(' ', '_')}.yml"
              with open(config_file, "w") as f:
                  yaml.dump(config, f, default_flow_style=False)
              
              print(f"üìã Config for {group_name}:")
              print(f"   üß¨ BioRxiv query: {group_config['query_biorxiv'][:100]}...")
              print(f"   üìÑ PubMed/ArXiv query: {group_config['query_pubmed_arxiv'][:100]}...")
              print(f"   üìä Limits: total={group_config['limit']}, per_db={group_config['limit_per_database']}")
              print(f"   üóÉÔ∏è Databases: {config['databases']}")
              print(f"   ü§ñ LLM: {config['LANGUAGE_MODEL']}")
              
              # Run PaperBee for this group
              try:
                  print(f"\nüöÄ Starting PaperBee for {group_name}...")
                  print(f"üìÖ Search window: ${{ steps.search_days.outputs.since_days }} days")
                  
                  # Set environment variable for group-specific header
                  env = os.environ.copy()
                  env["PAPERBEE_GROUP_NAME"] = group_name
                  env["PAPERBEE_GROUP_EMOJI"] = group_config["emoji"]
                  
                  result = subprocess.run([
                      "paperbee", "post", 
                      "--config", config_file, 
                      "--since", "${{ steps.search_days.outputs.since_days }}"
                  ], capture_output=True, text=True, timeout=1200, env=env)  # 20 min timeout per group
                  
                  print(f"\nüì§ PaperBee output for {group_name}:")
                  print("="*60)
                  print(result.stdout)
                  if result.stderr:
                      print(f"‚ö†Ô∏è Stderr: {result.stderr}")
                  print("="*60)
                  
                  if result.returncode == 0:
                      print(f"‚úÖ {group_name} completed successfully")
                      # Try to read results from output
                      output_lines = result.stdout.split('\n')
                      paper_count = 0
                      raw_count = 0
                      
                      # Parse various output patterns
                      for line in output_lines:
                          if 'papers selected after filtering' in line.lower():
                              try:
                                  paper_count = int(line.split()[0])
                              except:
                                  pass
                          elif 'found' in line.lower() and 'articles' in line.lower():
                              try:
                                  numbers = [int(s) for s in line.split() if s.isdigit()]
                                  if numbers:
                                      raw_count += numbers[0]
                              except:
                                  pass
                      
                      print(f"üìà Results for {group_name}: {raw_count} raw ‚Üí {paper_count} filtered")
                      
                      all_papers.append({
                          "group": group_name,
                          "emoji": group_config["emoji"],
                          "count": paper_count,
                          "raw_count": raw_count,
                          "status": "success"
                      })
                  else:
                      print(f"‚ùå {group_name} failed with return code {result.returncode}")
                      print(f"Error details: {result.stderr}")
                      all_papers.append({
                          "group": group_name,
                          "emoji": group_config["emoji"],
                          "count": 0,
                          "raw_count": 0,
                          "status": "failed"
                      })
                      
              except subprocess.TimeoutExpired:
                  print(f"‚è∞ {group_name} timed out after 20 minutes")
                  all_papers.append({
                      "group": group_name,
                      "emoji": group_config["emoji"],
                      "count": 0,
                      "raw_count": 0,
                      "status": "timeout"
                  })
              except Exception as e:
                  print(f"üí• {group_name} error: {str(e)}")
                  all_papers.append({
                      "group": group_name,
                      "emoji": group_config["emoji"],
                      "count": 0,
                      "raw_count": 0,
                      "status": "error"
                  })
              
              # Clean up config file
              try:
                  os.remove(config_file)
              except:
                  pass
          
          # Final summary for console only
          print(f"\nüìã FINAL SUMMARY:")
          total_papers = sum(p["count"] for p in all_papers if p["status"] == "success")
          total_raw = sum(p.get("raw_count", 0) for p in all_papers if p["status"] == "success")
          print(f"üî¢ Total papers: {total_raw} raw ‚Üí {total_papers} filtered")
          for paper_info in all_papers:
              raw_info = f" ({paper_info.get('raw_count', 0)} raw)" if paper_info.get('raw_count', 0) > 0 else ""
              print(f"  {paper_info['emoji']} {paper_info['group']}: {paper_info['count']} papers{raw_info} ({paper_info['status']})")
          
          print(f"\nüìù Note: Each group posted their papers separately to Slack")
          
          EOF
          
      - name: Clean up
        if: always()
        run: |
          rm -f google-credentials.json config_*.yml
