# .github/workflows/daily-papers.yml
name: Daily Paper Fetch (Gemini Fork)

on:
  schedule:
    - cron: '0 9 * * *'  # Daily at 9 AM UTC
  workflow_dispatch:

jobs:
  fetch-papers:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install -e .  # Install your modified fork (NOT the PyPI package)
          
      - name: Create Google credentials file
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS_JSON }}' > google-credentials.json
          
      - name: Create config file
        env:
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SPREADSHEET_ID }}
          NCBI_KEY: ${{ secrets.NCBI_API_KEY }}
          GEMINI_KEY: ${{ secrets.GEMINI_API_KEY }}
          SLACK_BOT: ${{ secrets.SLACK_BOT_TOKEN }}
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL_ID }}
          SLACK_APP: ${{ secrets.SLACK_APP_TOKEN }}
          SEARCH_QUERY: ${{ secrets.SEARCH_QUERY }}
          FILTER_PROMPT: ${{ secrets.FILTERING_PROMPT }}
        run: |
          # Create config using environment variables (safer for YAML parsing)
          # Create config using heredoc with proper YAML indentation
          cat > config.yml << 'CONFIGEOF'
          GOOGLE_SPREADSHEET_ID: "${GOOGLE_SHEET_ID}"
          GOOGLE_CREDENTIALS_JSON: "./google-credentials.json"
          NCBI_API_KEY: "${NCBI_KEY}"
          LOCAL_ROOT_DIR: "."
          
          query: "${SEARCH_QUERY:-[machine learning] OR [artificial intelligence] OR [deep learning]}"
          
          LLM_FILTERING: true
          LLM_PROVIDER: "openai"
          LANGUAGE_MODEL: "gemini-1.5-flash"
          OPENAI_API_KEY: "${GEMINI_KEY}"
          OPENAI_BASE_URL: "https://generativelanguage.googleapis.com/v1beta/openai/"
          
          FILTERING_PROMPT: "${FILTER_PROMPT:-You are a research assistant. Is this paper relevant to machine learning/AI research? Answer only yes or no.}"
          
          SLACK:
            is_posting_on: true
            bot_token: "${SLACK_BOT}"
            channel_id: "${SLACK_CHANNEL}"
            app_token: "${SLACK_APP}"
          
          TELEGRAM:
            is_posting_on: false
          ZULIP:
            is_posting_on: false
          CONFIGEOF
          
          # Now substitute the environment variables
          envsubst < config.yml > config_final.yml
          mv config_final.yml config.yml
          
      - name: Debug config file (quick check)
        run: |
          echo "=== Generated config.yml ==="
          cat config.yml
          echo ""
          echo "=== Query value specifically ==="
          python3 -c "
          import yaml
          with open('config.yml', 'r') as f:
              config = yaml.safe_load(f)
              print('Query:', repr(config.get('query', 'NOT FOUND')))
              print('Query length:', len(config.get('query', '')))
          "
          
      - name: Run PaperBee (your modified fork)
        run: |
          paperbee post --config config.yml --since 1
          
      - name: Clean up
        if: always()
        run: |
          rm -f google-credentials.json config.yml
